# -*- coding: utf-8 -*-
import os
import sys
import glob
import json
import datetime

sys.path.append('../')
import json
import time
from utils import utils
#schema:åç§°,æœ€æ–°ä»·,æ¶¨è·Œå¹…,æ¶¨è·Œé¢,æˆäº¤é‡,æˆäº¤é¢,æŒ¯å¹…,æœ€é«˜,æœ€ä½,ä»Šå¼€,æ˜¨æ”¶,é‡æ¯”,æ¢æ‰‹ç‡,å¸‚ç›ˆç‡-åŠ¨æ€,å¸‚å‡€ç‡,æ€»å¸‚å€¼,æµé€šå¸‚å€¼,æ¶¨é€Ÿ,5åˆ†é’Ÿæ¶¨è·Œ,60æ—¥æ¶¨è·Œå¹…,å¹´åˆè‡³ä»Šæ¶¨è·Œå¹…
"""
å¼ºåº¦åŒºé—´	æ•°å€¼èŒƒå›´	é¢œè‰²æ ‡è¯†
æåº¦å¼±åŠ¿	0.00 â‰¤ score < 0.50	ğŸ”´ çº¢è‰²
å¼±åŠ¿éœ‡è¡	0.50 â‰¤ score < 1.20	ğŸŸ  æ©™è‰²
ä¸­ç­‰æ´»è·ƒ	1.20 â‰¤ score < 2.00	ğŸŸ¡ é»„è‰²
å¼ºåŠ¿è¡Œæƒ…	2.00 â‰¤ score < 3.50	ğŸŸ¢ ç»¿è‰²
æç«¯è¿‡çƒ­	score â‰¥ 3.50	âš ï¸ ç´«è‰²

æç«¯è¿‡çƒ­éœ€è¦ç©ºä»“

åŠ¨æ€è°ƒæ•´æœºåˆ¶
ä¿®æ­£å› å­	å¯¹åŒºé—´çš„å½±å“
ç‚¸æ¿ç‡ >50%	å½“å‰åŒºé—´é™çº§ä¸€æ¡£ï¼ˆå¦‚1.45â†’å¼±åŠ¿éœ‡è¡ï¼‰
è¿æ¿é«˜åº¦ â‰¥7	å½“å‰åŒºé—´å‡çº§ä¸€æ¡£ï¼ˆå¦‚1.45â†’å¼ºåŠ¿è¡Œæƒ…ï¼‰
æ€»æ¶¨åœæ•° <30	å½“å‰åŒºé—´é™çº§ä¸€æ¡£

è¯†åˆ«ï¼š
å‡å¼ºåŠ¿ï¼ˆé«˜score+é«˜ç‚¸æ¿ç‡ï¼‰
çœŸå¯åŠ¨ï¼ˆä½score+ç‚¸æ¿ç‡å¿«é€Ÿä¸‹é™ï¼‰
"""


class DailyLimitStrength():
    def __init__(self, target_date):
        self.target_date = target_date
        # pools_file = './logs/dragon_v5_data.20241130'
        pools_file = self.get_latest_file('../logs', 'dragon_v5_data')
        # pools_file = '../logs\dragon_v5_data_20250417.json'
        print('[DEBUG]load_file:', pools_file)

        self.stock_dict = json.load(open(pools_file))
        print('[INIT]load target size:', len(self.stock_dict))
        print('[INIT]SUCCEED!')

    def get_latest_file(self, directory, prefix):
        # è·å–ç›®å½•ä¸‹æ‰€æœ‰ä»¥ 'prefix' å¼€å¤´çš„æ–‡ä»¶
        files = [
            f for f in glob.glob(os.path.join(directory, f"{prefix}*"))
            if f.endswith('.json')  # è¿‡æ»¤æ¡ä»¶
        ]
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œè¿”å› None
        if not files:
            return None

        # print(files)
        # ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸéƒ¨åˆ†ï¼Œå¹¶æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶
        def extract_date(file_path):
            # ç¤ºä¾‹æ–‡ä»¶åï¼šreverse_moving_average_bull_track_20250303.json
            base_name = os.path.basename(file_path)  # è·å–æ–‡ä»¶åéƒ¨åˆ†
            print(base_name)
            date_str = base_name.split('_')[-1].split('.')[0]  # åˆ†å‰²å‡º YYYYMMDD
            return int(date_str)  # è½¬æ¢ä¸ºæ•´æ•°ç”¨äºæ¯”è¾ƒ

        # æŒ‰æ—¥æœŸé™åºæ’åºåå–æœ€æ–°æ–‡ä»¶
        files_sorted = sorted(files, key=extract_date, reverse=True)
        latest_file = files_sorted[0]
        # latest_file = max(files, key=lambda x: x.split('.')[-1])  # æŒ‰æ—¥æœŸéƒ¨åˆ†æ¯”è¾ƒæ–‡ä»¶å
        print(f"[INIT]latest_file={latest_file}")
        return latest_file


    def do(self):
        """
        å‡çº¿äº¤å‰æ£€æµ‹å‡½æ•°ï¼ˆæ”¯æŒå¤šæ—¥è¿ç»­æ£€æµ‹ï¼‰
        :param stock_code: 6ä½è‚¡ç¥¨ä»£ç  å¦‚ï¼š'600519'
        :param days: éœ€è¦æ£€æµ‹çš„å¤©æ•°èŒƒå›´ï¼ˆé»˜è®¤æ£€æµ‹æœ€è¿‘2å¤©ï¼‰
        :return: bool æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…å‡ºç°äº¤å‰
        """
        # start_date='20210101',  # èµ·å§‹æ—¥æœŸè®¾ä¸ºè¶³å¤Ÿæ—©
        continue_limit_up_strength_dict = dict()
        ## è¿æ¿æ•°
        continue_limit_up_num = 0
        ## ç‚¸æ¿æ•°
        zha_limit_up_num = 0
        ## æ€»æ¶¨åœæ•°é‡
        all_limit_up_num = 0
        continue_limit_up_list = list()
        ## æ€»æ¶¨åœæ•°é‡
        for code, info_dict in self.stock_dict.items():
            name = info_dict.get("name", "")
            ## è¿ç»­æ¶¨åœä¸ªè‚¡æ•°é‡
            continuous_up_limit_days = info_dict.get("continuous_up_limit_days", -1)
            # å½“å¤©æœ€é«˜ä»·è§¦æ¿
            is_today_high_limit_up = info_dict.get("is_today_high_limit_up", -1)
            # å½“å¤©æ”¶ç›˜æ˜¯å¦æ¶¨åœ
            is_today_limit_up = info_dict.get("is_today_limit_up", -1)

            if continuous_up_limit_days == -1 or is_today_high_limit_up == -1 or is_today_limit_up == -1:
                continue
            # print(f"[DEBUG]{code}=={str(continuous_up_limit_days)}=={continuous_up_limit_days}")
            if continuous_up_limit_days >= 2:
                continue_limit_up_num += 1
                continue_limit_up_list.append(continuous_up_limit_days)
            if is_today_high_limit_up == 1 and is_today_limit_up <= 0:
                zha_limit_up_num += 1
            if is_today_limit_up:
                all_limit_up_num += 1
            # name = info_dict.get("name", "")
            # name = info_dict.get("name", "")

        continue_limit_up_strength_dict["continue_limit_up_num"] = continue_limit_up_num
        continue_limit_up_strength_dict["zha_limit_up_num"] = zha_limit_up_num
        continue_limit_up_strength_dict["all_limit_up_num"] = all_limit_up_num
        continue_limit_up_strength_dict["continue_limit_up_list"] = continue_limit_up_list
        score, zha_rate, avg_continue_limit_up = self.calculate_board_strength(continue_limit_up_strength_dict)
        continue_limit_up_strength_dict["score"] = score
        continue_limit_up_strength_dict["zha_rate"] = zha_rate
        continue_limit_up_strength_dict["avg_continue_limit_up"] = avg_continue_limit_up
        #print(rate)
        return continue_limit_up_strength_dict

    def calculate_board_strength(self, board_data):
        """
        è®¡ç®—è¿æ¿å¼ºåº¦

        :param board_data: dict, è¿æ¿åŠå¸‚åœºæƒ…ç»ªæ•°æ®ï¼Œä¾‹å¦‚
                           {
                               "è¿æ¿æ•°": 15,
                               "æ€»æ¶¨åœæ•°": 40,
                               "è¿æ¿é«˜åº¦åˆ—è¡¨": [2, 3, 2, 4, 5, 1],  # æ¯ä¸ªè¿æ¿è‚¡ç¥¨çš„é«˜åº¦
                               "ç‚¸æ¿æ•°": 10
                           }
        :return: float, è¿æ¿å¼ºåº¦
        """
        # è¿æ¿æ•°
        continue_limit_up_num = board_data['continue_limit_up_num']
        # æ€»æ¶¨åœæ•°
        all_limit_up_num = board_data['all_limit_up_num']
        # ç‚¸æ¿æ•°
        zha_limit_up_num = board_data['zha_limit_up_num']
        # è¿æ¿é«˜åº¦åˆ—è¡¨
        continue_limit_up_list = board_data['continue_limit_up_list']

        if all_limit_up_num == 0:  # é¿å…é™¤ä»¥é›¶
            return 0, 0, 0

        # è®¡ç®—å¹³å‡è¿æ¿é«˜åº¦
        avg_continue_limit_up = 0
        if continue_limit_up_num > 0:
            avg_continue_limit_up = sum(continue_limit_up_list) / len(continue_limit_up_list)
        else:
            avg_continue_limit_up = 0

        # è®¡ç®—ç‚¸æ¿ç‡
        zha_rate = zha_limit_up_num / (zha_limit_up_num + continue_limit_up_num)  # ç‚¸æ¿å°è¯•æ€»æ•° = ç‚¸æ¿æ•° + è¿æ¿æ•°

        # ç»¼åˆå…¬å¼
        # è¿æ¿å¼ºåº¦ = (è¿æ¿æ•° * å¹³å‡è¿æ¿é«˜åº¦) / (æ€»æ¶¨åœæ•° * ç‚¸æ¿ç‡ + 1)
        strength = (continue_limit_up_num  * avg_continue_limit_up) / (all_limit_up_num*zha_rate + 1.0)
        return round(strength, 4), zha_rate, avg_continue_limit_up

if __name__ == '__main__':
    start  = time.time()

    # target_date = "20500101"
    # target_date = "20250418"
    # formatted_datetime = target_date
    formatted_datetime = datetime.datetime.now().strftime("%Y%m%d")
    checker = DailyLimitStrength(formatted_datetime)

    out_file = '../logs/v1_daily_limit_strength_data_' + formatted_datetime
    stc_json = open(out_file + '.json', 'w')
    stc_dict = checker.do()
    stc_str = json.dumps(stc_dict, ensure_ascii=False, indent=4)
    stc_json.write(stc_str + '\n')
    meta = open(out_file+'.meta', 'w')
    meta_dict = dict()
    meta_dict["pools_size"] = len(stc_dict)
    meta_dict["spend_time"] = ( time.time() - start )
    # row_line = '\t'.join(('pools_size:', str(len(stc_dict)), "; target_num:", str(target_num)))
    row_line = json.dumps(meta_dict, ensure_ascii=False, indent=4)
    meta.write(row_line+'\n')
